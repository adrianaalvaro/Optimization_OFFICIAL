{"cells":[{"cell_type":"markdown","metadata":{"id":"xamF3BcFCT9A"},"source":["# Lab 5: 20/11/2023\n","\n","\n","## Constrained optimization: equality and inequality constraints\n","\n","### Dafni Tziakouri\n","\n","### Adriana Álvaro"]},{"cell_type":"markdown","metadata":{},"source":["## 2 Implementation of the dual formulation"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"WKWUrXsRAech"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from QPGC import QPGenericConstraints "]},{"cell_type":"markdown","metadata":{},"source":["We will start by generating the 2 datasets as specified in the pdf:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def generate_dataset(n, separable=True):\n","    mean1 = np.array([0., 0.])\n","    cov1 = np.array([[1., -0.9], [-0.9, 1.]])\n","\n","    if separable:\n","        mean2 = np.array([3., 6.])\n","        cov2 = np.array([[1., 0.], [0., 1.]])\n","    else:\n","        mean2 = np.array([1., 2.])\n","        cov2 = np.array([[1., 0.], [0., 1.]])\n","\n","    pos_samples = np.random.multivariate_normal(mean1, cov1, n)\n","    neg_samples = np.random.multivariate_normal(mean2, cov2, n)\n","\n","    X = np.concatenate((pos_samples, neg_samples)).T\n","    y = np.concatenate((np.ones(n), -np.ones(n)))\n","\n","    return X, y"]},{"cell_type":"markdown","metadata":{},"source":["Now, we will define the matrices for the optimization problem, equation (8). To solve this problem we will use the QPGenericConstraints library and the equation (9)."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def generate_matrices(X, y, K):\n","    \"\"\"\n","    Generates matrices and vectors for the quadratic programming problem based on input data.\n","\n","    Parameters:\n","    - X: Data matrix with features.\n","    - y: Labels (1 for positive class, -1 for negative class).\n","    - K: Scalar parameter.\n","\n","    Returns:\n","    - A: Matrix representing the labels for the quadratic programming problem.\n","    - b: Vector representing the right-hand side of the linear equality constraint.\n","    - C: Matrix representing the inequality constraints.\n","    - d: Vector representing the right-hand side of the inequality constraints.\n","    - G: Matrix for the quadratic term in the objective function.\n","    - g: Vector for the linear term in the objective function.\n","    \"\"\"\n","    n = X.shape[1]  # Number of samples\n","    p = 1  # Dimensionality of p (shape of A)\n","    m = 2 * n  # Number of inequality constraints (given in the exercise)\n","    N = n + p + 2 * m  # Dimension of the KKT Matrix (given in KKT System desc.)\n","\n","    A = y.reshape(n, p)  # Matrix A for the linear equality constraint A.T * x = b\n","    b = np.zeros(p)  # Vector b in R^{p} (all zeros in A.T * x = b)\n","\n","    # Matrix C for the inequality constraints [I_n, -I_n]\n","    C = np.concatenate((np.eye(n), -np.eye(n)), axis=1)\n","\n","    # Vector d for the inequality constraints [0, -K]\n","    d = np.concatenate((np.zeros(n), -K * np.ones(n)))\n","\n","    Y = np.diag(y)  # Transformation needed to compute the matrix G\n","    G = np.dot(np.dot(Y, X.T), np.dot(X, Y))  # Matrix G for the quadratic term in the objective function\n","    g = -np.ones(n)  # Vector g for the linear term in the objective function (given by the exercise: Normal Distribution)\n","\n","    return A, b, C, d, G, g\n"]},{"cell_type":"markdown","metadata":{},"source":["After our problem will be minimized, we will need to compute the hyperplane. Therefore, we create a function in which we calculate the hyperplane parameters (w,b) based on the solution to the quadratic problem, alpha."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def compute_hyperplane(alpha, X, y):\n","  # Choosing the \"best\" pair of points that contribute to defining the hyperplane\n","    min_dist = np.inf\n","    best_pair = None\n","    for i in range(X.shape[1]):\n","        for j in range(X.shape[1]):\n","            # Check if the points have different labels (one positive and one negative)\n","            if y[i] * y[j] < 0:\n","                # Calculate the Euclidean distance between the points\n","                dist = np.linalg.norm(X.T[i, :] - X.T[j, :])\n","                # Update the best pair if the current distance is smaller\n","                if dist < min_dist:\n","                    min_dist = dist\n","                    best_pair = (i, j)\n","\n","    # Compute the weight vector w using the formula: w = ∑(alpha_i * y_i * x_i)\n","    w = np.sum(alpha * y * X, axis=1)\n","\n","    # Compute the bias term b using the chosen \"best\" point and the weight vector: b = y_best - w^T * x_best\n","    b = y[best_pair[0]] - np.dot(w.T, X.T[best_pair[0], :])\n","\n","    return w, b\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Experiment1:**  You are recommended to begin with the simplest case, i.e. the case in which data is separable, and with a small dataset (2 points for each class, for instance). You are recommended to start with a relatively small value of $K$, e.g. $K = 1$. Plot the hyperplane $f(x) = wT x + b = 0$, as well as the hyperplane at distance −1 and 1 respectively. Check if the hyperplane separates correctly the set of points and check that the hyperplanes at distance −1 and 1 “touch” the support vectors.\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'QPGenericConstraints' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\35796\\OneDrive\\Desktop\\Maters Fall Semester 2023\\Optimization\\Labs\\Lab5\\Optimization\\Practical_5_6\\Lab5_6.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/35796/OneDrive/Desktop/Maters%20Fall%20Semester%202023/Optimization/Labs/Lab5/Optimization/Practical_5_6/Lab5_6.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m A, b, C, d, G, g \u001b[39m=\u001b[39m generate_matrices(X, y, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/35796/OneDrive/Desktop/Maters%20Fall%20Semester%202023/Optimization/Labs/Lab5/Optimization/Practical_5_6/Lab5_6.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Compute alpha \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/35796/OneDrive/Desktop/Maters%20Fall%20Semester%202023/Optimization/Labs/Lab5/Optimization/Practical_5_6/Lab5_6.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m alpha \u001b[39m=\u001b[39m QPGenericConstraints(G, g, A, C, b, d)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/35796/OneDrive/Desktop/Maters%20Fall%20Semester%202023/Optimization/Labs/Lab5/Optimization/Practical_5_6/Lab5_6.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Compute hyperplane\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/35796/OneDrive/Desktop/Maters%20Fall%20Semester%202023/Optimization/Labs/Lab5/Optimization/Practical_5_6/Lab5_6.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m w, b \u001b[39m=\u001b[39m compute_hyperplane(alpha, X, y)\n","\u001b[1;31mNameError\u001b[0m: name 'QPGenericConstraints' is not defined"]}],"source":["# Generate dataset\n","X, y = generate_dataset(2)\n","\n","# Generate matrices\n","A, b, C, d, G, g = generate_matrices(X, y, 1)\n","\n","# Compute alpha \n","alpha = QPGenericConstraints(G, g, A, C, b, d)\n","\n","# Compute hyperplane\n","w, b = compute_hyperplane(alpha, X, y)\n","\n","# Plot points, margins and hyperplane\n","linespace = np.linspace(-5, 5, 100)\n","\n","plt.scatter(X[0,:], X[1,:], c=y)\n","plt.plot(linespace, -(w[0]*linespace + b) / w[1], 'r')\n","plt.plot(linespace, -(w[0]*linespace + b+1) / w[1], 'g')\n","plt.plot(linespace, -(w[0]*linespace + b-1) / w[1], 'g')\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOGwcBs3VFfvO6zgnDXLUrt","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
